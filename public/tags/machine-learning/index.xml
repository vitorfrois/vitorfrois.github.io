<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Vítor Fróis</title>
    <link>http://localhost:1313/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Vítor Fróis</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 May 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Visualizing the Bias-Variance tradeoff</title>
      <link>http://localhost:1313/bias/</link>
      <pubDate>Tue, 13 May 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/bias/</guid>
      <description>&lt;p&gt;It’s not easy to find equilibrium between complex and simple when&#xA;training a Machine Learning model. This could be difference between a&#xA;million dollars loss and huge win or between classifying your pets&#xA;correctly. The explanations about Bias-Variance tradeoff never convinced&#xA;me, so I decided explain my own way: what’s really behind this&#xA;dilemma?&lt;/p&gt;&#xA;&lt;p&gt;Imagine everyday lots of dogs and cats pass through your window. Some&#xA;of them are big, some are small ones. You decide to investigate wheter&#xA;you could classify the pets using their heights and weights, so you take&#xA;measures for a bunch of animals. Cats are usually smaller and lighter.&#xA;Dogs are generally bigger or heavier.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Support Vector Machines</title>
      <link>http://localhost:1313/support_vector/</link>
      <pubDate>Wed, 19 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/support_vector/</guid>
      <description>&lt;p&gt;Support Vectors are definetly one of my favorite ideias in Machine&#xA;Learning. It is such a simple concept, but when combined with some math,&#xA;turns into a powerful tool. Vladimir Vapnik came with the ideia of&#xA;Support Vectors in the middle of the 60’s, but only in 1992 a group of&#xA;scientists discovered a trick that could transform the linear model into&#xA;a nonlinear one.&lt;/p&gt;&#xA;&lt;h2 id=&#34;support-vector-machines&#34;&gt;Support Vector Machines&lt;/h2&gt;&#xA;&lt;p&gt;Suppose that two linear separable classes lies in a space. To create&#xA;a model, we should find the best way to draw such a separation. Decision&#xA;trees, neural networks came with theier own ideia, but Support Vector&#xA;Machines (SVM) looks not for a line, but a lane that best does that&#xA;separation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Creating a Chess Bot</title>
      <link>http://localhost:1313/chess-bot/</link>
      <pubDate>Tue, 26 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/chess-bot/</guid>
      <description>&lt;p&gt;Unite two passions like chess and computers is an old hobby that&#xA;started long time ago when I created an website to agregate chess info&#xA;around the net. There was a long time ago, and having the opportunity to&#xA;make another project involving chess make me curious.&lt;/p&gt;&#xA;&lt;p&gt;The youtuber &lt;a&#xA;href=&#34;https://www.youtube.com/c/SebastianLague&#34;&gt;Sebastian Lague&lt;/a&gt;&#xA;developed a challenge between its followers with the objective of&#xA;creating the most powerful Chess Bot within a limit of characters in C#.&#xA;Together with some university colleagues, we created the &lt;a&#xA;href=&#34;https://github.com/icmc-data/tiny-chess-bots&#34;&gt;Saint Charles&#xA;Bot&lt;/a&gt; (named after our campus city).&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
